connection:
  host: 'localhost'
  port: 2000
  timeout: 10 # seconds

visualization:

  birds_eye_camera: # setup a camera following the ego vehicle, display on a separate openCV window
    active: False # whether or not to spawn it
    image_size_x: 800 #px
    image_size_y: 600 #px
    fov: 90 # deg
    z: 50 # how high the camera is w.r.t. the ego. In meters

  world: # spawns an extra window that draws the entire world (e.g. road network, traffic lights, other RUs, ego...etc)
    active: False

agent:
  name: 'Custom' # Choose from carla navigation: Basic, ConstantVelocity, Behavior, or Custom
  speed: 30 # Target speed. Only relevant for Basic and ConstantVelocity agents
  behavior: 'normal' #Only applicable to BehaviorAgent. Choose between 'cautions', 'normal' or 'aggressive'
  loop: True # Roam around indefinitely (i.e. sets new destination once original one is reached)

  perception: None # ToDo: Allow pre-defined options or custom implementation
  prediction: None # ToDo: Allow pre-defined options or custom implementation
  planning: None # ToDo: Allow pre-defined options or custom implementation
  control: None # ToDo: Allow pre-defined options or custom implementation


misc:
  spectator_follows_ego: True # Spectator follows ego from the top (equivalent effect as setting up a separate birds_eye cam)
  show_times_on_console: True # Share of computation time spent on each task (visualization, planning, perception, preiction...etc) is shown on console

logging:
  additional_data: True  # https://carla.readthedocs.io/en/0.9.15/adv_recorder/#recording

prediction:  # ToDo: move as agent's subconfig?
  model: MultiModalConstantVelocity # match with class name. Note: currently it doesn't automatically load in code. Need to manually update navigation_agents.py. ToDo.
  alias: CVX
  predict_heading: False # most predictors only output 2d predictions (x-y positions). If this is true, theta will be computed from it
  predict_z: True # most predictors only output 2d predictions (x-y positions). If this is true, z will predicted or kept from current z
  prediction_horizon: 10 # in seconds
  prediction_step: 0.1 # in seconds

  n_trajectories: 3 # applicable to multimodal predictions

planner: 
  model: MPCPlanner
  alias: MPC
  N: 10 # prediction horizon
  detection_radius: 50 # meters
  dt: 0.1 # sampling time
  ca_radius: 2.8 # collision avoidance radius
  v_des: 5 #(m/s) desired velocity
  nx: 7 # number of states
  nu: 2 # number of inputs

  steering_rate_limit:  0.3  #rad/s
  jerk_limit: 0.9   #m/s^3 (jerk limit)
  v_min: 0
  v_max: 10
  a_min: -4
  a_max: 3
  ey_lim: 0.5
  max_steering: 0.6 #rad